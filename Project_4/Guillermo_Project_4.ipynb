{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guillermo Kopp's Project 4 - Bayesian Calculations\n",
    "\n",
    "**Exercise 1:**\n",
    "\n",
    "Create a Bayesian Regression class that takes a log posteriori, data points, number of walkers, etc as initilization and provides all required methods and attributes required for Bayesian Regression Problems. The class should also be able to provide an integration method that allows you to integrate with respect to the posteriori distribution. Additionally, the class should allow to calculate all probabilities including the predictive distribution. Also include methods for visualization such as corner maps. Even though this class is part of a project you should consider it as your first self build Data Science tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "The data below is in the form (x,t) and represents the height x of the tide at a specific location over the course of a day. Time is represented by the variable t. Build a Bayesian Regression Model using your class from Exercise 1. Show us what your new class can do!\n",
    "* Start by describing the data. What type of functional behavior do you anticipate? \n",
    "* Use your model to make a prediction about the future. \n",
    "* Create a corner plot.\n",
    "* What can you say about the variance of your model parameters and what does that mean?\n",
    "\n",
    "*Bonus!!* \n",
    "* What is the probability that the tide is higher than 15 during a day.\n",
    "* What is the probability that the tide is lower than 5 during a day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below You will notice that there are two functions \n",
    "* The first uses 4 omegas and takes a total of five dimensions \n",
    "* The second uses 3 omegas and takes a total of four dimensions\n",
    "\n",
    "I have added what I understood for calculating the probabilities\n",
    "\n",
    "The challenges I faced were mostly with linearizing the function and picking the right likelihood to start out with. I would have liked to include fucntionality to change the number of dimensions and possibly the likelihood too but i really like my bed and this seems to me like a suitable MVP.\n",
    "\n",
    "I would have also liked to have plaued around with the model more as well as limiting the parameters but I want to go to bed.\n",
    "\n",
    "The variance for the model parameters tells me the level of uncertainty for that parameter, as it becomes smaller the uncertainty shrinks. The mean is the expected value for that parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "global data\n",
    "\n",
    "data = [(12.676817787115283, 4.840968499185621),\n",
    " (3.0635215093963133, 3.14922059397124),\n",
    " (8.9357879700357667, 5.431164887988198),\n",
    " (13.150389074317657, 0.2734372074578954),\n",
    " (12.925121692101902, 5.02106046462978),\n",
    " (10.269853674176913, 3.7776881451798454),\n",
    " (8.5618490817719284, 1.7531496843623315),\n",
    " (11.652310665546354, 0.13740741237008774),\n",
    " (15.785676964359141, 0.1589401373556326),\n",
    " (10.709910995988764, 1.405806821770987),\n",
    " (7.1341191045745171, 5.791539306670335),\n",
    " (21.883583042704814, 5.375575646320319),\n",
    " (9.3509495831601566, 1.5283167578387404),\n",
    " (8.9421204746670746, 1.2943521169392636),\n",
    " (7.9107785943448947, 2.41326855106268),\n",
    " (6.6761875778137583, 5.605375440538395),\n",
    " (11.650996974527924, 4.935997586415922),\n",
    " (17.290020321649969, 5.274010438371379),\n",
    " (13.06634684581484, 0.2347909715055829),\n",
    " (9.2602800850011402, 1.9716673533870746),\n",
    " (13.919837953941261, 5.528598466510076),\n",
    " (7.9171739378319606, 5.84750784658713),\n",
    " (12.864499776009934, 0.8278490177929644),\n",
    " (10.571617689971236, 2.36723797633488),\n",
    " (15.697626403745566, 6.217581078023053),\n",
    " (6.9542139194365262, 3.1860455750181425),\n",
    " (13.120156492593505, 4.864593354788696),\n",
    " (11.454973850882114, 1.8798442605946453),\n",
    " (10.614021877252608, 0.8044135861997307),\n",
    " (7.568300166951679, 2.673290291826998),\n",
    " (10.183500038106194, 1.309623551484031),\n",
    " (13.503996786942462, 0.04020573153381622),\n",
    " (14.908454853041013, 5.049774593191907),\n",
    " (16.502324161297746, 5.406433813862234),\n",
    " (7.7831240000772652, 5.45198929005635),\n",
    " (2.7144705188261025, 4.10012261788714),\n",
    " (6.3268913726889187, 5.6611505113173575),\n",
    " (9.343465517423013, 3.2971190116581632),\n",
    " (10.029091959312348, 0.5986208146884879),\n",
    " (12.078957723820951, 0.3853462849024228),\n",
    " (12.542705834818268, 1.5820979005652125),\n",
    " (9.8489274946698337, 2.6735253975153426),\n",
    " (11.349497927312719, 1.1055955472925354),\n",
    " (11.06556939865615, 2.5611692213120962),\n",
    " (11.242786106546351, 0.6500902431293415),\n",
    " (7.5720317139333542, 3.4428084142928075),\n",
    " (10.19301456907124, 2.427329872753534),\n",
    " (11.688185995125892, 0.14941531339444405),\n",
    " (13.321217017544326, 4.226862591173392),\n",
    " (9.2226853401109601, 2.3990630763955374),\n",
    " (7.0737562512314449, 0.8821159241146929),\n",
    " (5.5158907409668556, 2.287657630597947),\n",
    " (5.2424711689478309, 3.4418528431658317),\n",
    " (11.826235109408199, 3.3038133315910185),\n",
    " (6.2478202112864949, 3.7493402648869223),\n",
    " (7.2776616254733053, 2.666108760536187),\n",
    " (14.728663233221567, 5.923646379789856),\n",
    " (11.088563226667782, 2.974838497958867),\n",
    " (11.458847468046265, 1.2931851555147837),\n",
    " (4.0709653063610656, 2.4390760560779694),\n",
    " (15.530850378396899, 0.7685325485891545),\n",
    " (11.615168564683962, 2.7271570577326223),\n",
    " (10.632288760396049, 5.37570954124343),\n",
    " (6.9102179020649883, 1.9530381191410195),\n",
    " (7.1344237045084675, 1.6373486764522571),\n",
    " (2.4211573415830188, 2.810112760589519),\n",
    " (7.6108111175276107, 4.181915055702122),\n",
    " (9.6538205198090434, 4.444382820070389),\n",
    " (8.1905132263562983, 3.0534156042900285),\n",
    " (7.4546566492388493, 5.388475797989607),\n",
    " (14.087818085722649, 4.961727257154151),\n",
    " (7.2780971375915371, 2.54178907740794),\n",
    " (13.49355600611988, 2.493864649506947),\n",
    " (7.1166182479555999, 3.0195450895358524),\n",
    " (13.861336288014931, 6.246482002469356),\n",
    " (9.9498449141955589, 1.5817110088866608),\n",
    " (12.090250168282912, 3.990269038499848),\n",
    " (14.0111497595614, 0.9108297343631235),\n",
    " (9.3928518482934216, 3.3950553805254793),\n",
    " (8.2709147406350212, 3.214121983305056),\n",
    " (8.386404092046515, 2.1119573572471135),\n",
    " (6.9673744914092852, 2.2083135342567983),\n",
    " (9.5162641851488523, 3.2184133097802943),\n",
    " (17.967580316152478, 3.965622119805391),\n",
    " (15.832368008468372, 0.828357131652206),\n",
    " (5.3317615928107358, 2.6644501925548774),\n",
    " (5.8971983697046877, 3.0341229253117494),\n",
    " (17.963906775041007, 6.0469989006758444),\n",
    " (5.6300726881847361, 2.4077579346402826),\n",
    " (11.348534324413565, 3.8699231013565725),\n",
    " (10.028167958705753, 1.9397974132848168),\n",
    " (14.062219131934697, 4.41603067403343),\n",
    " (9.10707255345568, 0.8011371320017451),\n",
    " (10.567716164156263, 4.450436137829604),\n",
    " (10.928830310193101, 4.839816330906595),\n",
    " (11.681478622619728, 0.8572196990559613),\n",
    " (11.538949263967641, 5.760338188965996),\n",
    " (10.978084516398958, 4.49756314191279),\n",
    " (12.818751132975834, 4.411544813273495),\n",
    " (6.7181748281785731, 5.484421751460473)]\n",
    "\n",
    "# prob function is outside of the function because doing it inside gets messy due to the x parameter in prob that when in the class\n",
    "# class requires an actual parameter to be passed when it is being defined/instantiated as a method\n",
    "\n",
    "def lnprob(x):\n",
    "    N = len(data)\n",
    "    if x[4] < 0 or x[2] > (2*np.pi) or x[2] < 0:\n",
    "        return -np.infty\n",
    "    else:\n",
    "        #return (-0.5*x[4]*np.sum([(e[0] - (x[0]+ x[1]*(x[2] *np.sin(x[3]*e[1]) + np.cos(x[3]*e[1]))))**2 for e in data]) + 0.5*N*np.log(x[4]) - 0.5*(x[0]**2+ x[1]**2 + x[2]**2 +x[3]**2) - x[4])\n",
    "        #return ( -0.5 * x[4] * np.sum([(e[0] - (x[0] + x[1] * np.sin(x[2] * e[1] + x[3]))) ** 2 for e in data]) + 0.5 * N * np.log(\n",
    "           # x[4]) - 0.5 * (x[0] ** 2 + x[1] ** 2 + x[2] ** 2 + x[3] ** 2) - x[4])\n",
    "        return(-0.5*x[4] * np.sum([(e[0]-(x[0] + (x[1]*(x[2]*(np.sin(e[1])*np.cos(e[1])*np.cos(x[3])) + x[2]*(np.sin(e[1])*np.cos(e[1])*np.sin(x[3]))))))**2 for e in data]) + 0.5*N*np.log(x[4]) - 0.5*(x[0]**2+ x[1]**2 + x[2]**2 +x[3]**2) - x[4])\n",
    "        #return(-0.5*x[4] * np.sum([(e[0]-x[0] + x[1]*(x[2]*np.sin(e[1])+x[3]*np.cos(e[1])))**2 for e in data]) + 0.5*N*np.log(x[4]) - 0.5*(x[0]**2+ x[1]**2 + x[2]**2 +x[3]**2) - x[4])\n",
    "class bayes:\n",
    "\n",
    "\n",
    "    def __init__(self, lnprob):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import matplotlib\n",
    "        from matplotlib import pyplot as plt\n",
    "        #self.data2 = data\n",
    "        self.lnprob = lnprob\n",
    "\n",
    "\n",
    "\n",
    "    def create_scatter_plot(self, data2):\n",
    "        data3 = pd.DataFrame(data2) # converted data into panda dataframe\n",
    "        data4 = data2\n",
    "        X1 = sum([x[1] for x in data2])\n",
    "        T = sum([x[0] for x in data2])\n",
    "        X2 = sum([x[1]**2 for x in data2])\n",
    "        T2 = sum([x[0]**2 for x in data2])\n",
    "        XT = sum([x[1]*x[0] for x in data2])\n",
    "        N = len(data2)\n",
    "        self.DeployEMCEE(data4, data3)\n",
    "        #print X1\n",
    "        #return data4, data3\n",
    "\n",
    "    def MonteCarlo(self,f, samples):\n",
    "        N = len(samples)\n",
    "        return 1 / float(N) * sum([f(e) for e in samples])\n",
    "\n",
    "  # unleash the walking dead!  \n",
    "    def set_walkers(self):\n",
    "        walkers = int(raw_input(\"please select an even number of walkers\"))\n",
    "        if walkers % 2 == 0:\n",
    "          pass\n",
    "        else:\n",
    "           walkers = int(raw_input(\"You did not select an even number of walkers to input please try again: \"))\n",
    "        return walkers\n",
    "\n",
    "\n",
    "    def set_dimensions(self):\n",
    "        ndim = int(raw_input(\"please select the number of dimensions Hint: there are five dimensions\"))\n",
    "        return ndim\n",
    "\n",
    " # This is the main part og the code   \n",
    "    def DeployEMCEE(self, data4, data3):\n",
    "        import emcee\n",
    "        import time\n",
    "        ndim = self.set_dimensions()\n",
    "        nwalkers = self.set_walkers()\n",
    "        print \"Go grab some decaf coffee this might take awhile!\"\n",
    "        start = time.time()\n",
    "        p0 = np.random.rand(nwalkers * ndim).reshape((nwalkers, ndim)) * 10\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, self.lnprob)\n",
    "        pos, prob, state = sampler.run_mcmc(p0, 1000)\n",
    "        sampler.reset()\n",
    "        pos, prob, state = sampler.run_mcmc(pos, 100000)\n",
    "        samples = sampler.flatchain\n",
    "        end = time.time()\n",
    "        timetaken = end - start\n",
    "\n",
    "\n",
    "        omega0 = self.MonteCarlo(lambda x: x[0], samples)\n",
    "        omega1 = self.MonteCarlo(lambda x: x[1], samples)\n",
    "        omega2 = self.MonteCarlo(lambda x: x[2], samples)\n",
    "        omega3 = self.MonteCarlo(lambda x: x[3], samples)\n",
    "        lam = self.MonteCarlo(lambda x: x[4], samples)\n",
    "        print ('o0 = {0}, o1 = {1}, o2 = {2}, o3 = {3}, l = {4}'.format(omega0, omega1, omega2, omega3, lam))\n",
    "        self.plot_linear(data3, omega0,omega1,omega2,omega3)\n",
    "        self.plot_prmtrs_dnsty(samples)\n",
    "        self.predictive(samples)\n",
    "        self.corner_plt(samples)\n",
    "        plt.show()\n",
    "        self.probhigher15(samples)\n",
    "        self.problower5(samples)\n",
    "        print 'done'\n",
    "        print \"Your runtime in seconds {0}\".format(timetaken)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def plot_linear(self, data3, omega0,omega1,omega2,omega3):\n",
    "        X = data3[0]\n",
    "        T = data3[1]\n",
    "        Xval = np.arange(0, 11)\n",
    "        Reg = [omega0 + omega1 * np.sin(omega2*x + omega3) for x in Xval]\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "        ax.scatter(T, X)\n",
    "        ax.plot(Xval, Reg, label='Regression', color='red')\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel('$X_t$')\n",
    "        ax.legend(loc='best', fontsize='small')\n",
    "        ax.grid();\n",
    "\n",
    "    \n",
    "    def plot_prmtrs_dnsty(self, samples):\n",
    "        data3 = pd.DataFrame(samples, columns=['Omega0', 'Omega1', 'Omega2', 'Omega3', 'Lambda'])\n",
    "        data3.plot(kind='density', xlim =(-5, 10), ylim = (0,5))\n",
    "        \n",
    "    def corner_plt(self, samples):\n",
    "        import corner\n",
    "        fig = corner.corner(samples, labels=[\"$\\omega_0$\", \"$\\omega_1$\",\"$\\omega_2$\", \"$\\omega_3$\",\"$\\lambda$\"])\n",
    "\n",
    "    def predictive(self, samples):\n",
    "        f = lambda x, t: lambda d: np.sqrt(d[4]/(2*np.pi))*np.exp(-0.5*(x - (d[0] + d[1]*np.sin(d[2]*t + d[3]))**2))\n",
    "        predictiveDist = lambda t: np.vectorize(lambda x: self.MonteCarlo(lambda d: f(x,t)(d), samples))\n",
    "        X = np.arange(1, 50, 1)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "        ax.plot(X,predictiveDist(14)(X))\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel('$X_t$')\n",
    "        \n",
    "        #attempt at the bonus\n",
    "    def probhigher15(self, samples):\n",
    "        f = lambda d: d[0] + d[1] * np.sin(d[2]*(np.random.uniform(0,2*np.pi,1)) + d[3])\n",
    "        Filter1 = [1 for e in samples if f(e) >15]\n",
    "        print \"probability higher than fifteen: {0}\".format(len(Filter1)/float(len(samples)))\n",
    "    def problower5(self, samples):\n",
    "        f = lambda d: d[0] + d[1] * np.sin(d[2]*(np.random.uniform(0,2*np.pi,1)) + d[3])\n",
    "        Filter1 = [1 for e in samples if f(e) <5]\n",
    "        print \"probability lower than five: {0}\".format(len(Filter1)/float(len(samples)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# please start me\n",
    "\n",
    "newcl = bayes(lnprob)\n",
    "newcl.create_scatter_plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "global data\n",
    "\n",
    "data = [(12.676817787115283, 4.840968499185621),\n",
    " (3.0635215093963133, 3.14922059397124),\n",
    " (8.9357879700357667, 5.431164887988198),\n",
    " (13.150389074317657, 0.2734372074578954),\n",
    " (12.925121692101902, 5.02106046462978),\n",
    " (10.269853674176913, 3.7776881451798454),\n",
    " (8.5618490817719284, 1.7531496843623315),\n",
    " (11.652310665546354, 0.13740741237008774),\n",
    " (15.785676964359141, 0.1589401373556326),\n",
    " (10.709910995988764, 1.405806821770987),\n",
    " (7.1341191045745171, 5.791539306670335),\n",
    " (21.883583042704814, 5.375575646320319),\n",
    " (9.3509495831601566, 1.5283167578387404),\n",
    " (8.9421204746670746, 1.2943521169392636),\n",
    " (7.9107785943448947, 2.41326855106268),\n",
    " (6.6761875778137583, 5.605375440538395),\n",
    " (11.650996974527924, 4.935997586415922),\n",
    " (17.290020321649969, 5.274010438371379),\n",
    " (13.06634684581484, 0.2347909715055829),\n",
    " (9.2602800850011402, 1.9716673533870746),\n",
    " (13.919837953941261, 5.528598466510076),\n",
    " (7.9171739378319606, 5.84750784658713),\n",
    " (12.864499776009934, 0.8278490177929644),\n",
    " (10.571617689971236, 2.36723797633488),\n",
    " (15.697626403745566, 6.217581078023053),\n",
    " (6.9542139194365262, 3.1860455750181425),\n",
    " (13.120156492593505, 4.864593354788696),\n",
    " (11.454973850882114, 1.8798442605946453),\n",
    " (10.614021877252608, 0.8044135861997307),\n",
    " (7.568300166951679, 2.673290291826998),\n",
    " (10.183500038106194, 1.309623551484031),\n",
    " (13.503996786942462, 0.04020573153381622),\n",
    " (14.908454853041013, 5.049774593191907),\n",
    " (16.502324161297746, 5.406433813862234),\n",
    " (7.7831240000772652, 5.45198929005635),\n",
    " (2.7144705188261025, 4.10012261788714),\n",
    " (6.3268913726889187, 5.6611505113173575),\n",
    " (9.343465517423013, 3.2971190116581632),\n",
    " (10.029091959312348, 0.5986208146884879),\n",
    " (12.078957723820951, 0.3853462849024228),\n",
    " (12.542705834818268, 1.5820979005652125),\n",
    " (9.8489274946698337, 2.6735253975153426),\n",
    " (11.349497927312719, 1.1055955472925354),\n",
    " (11.06556939865615, 2.5611692213120962),\n",
    " (11.242786106546351, 0.6500902431293415),\n",
    " (7.5720317139333542, 3.4428084142928075),\n",
    " (10.19301456907124, 2.427329872753534),\n",
    " (11.688185995125892, 0.14941531339444405),\n",
    " (13.321217017544326, 4.226862591173392),\n",
    " (9.2226853401109601, 2.3990630763955374),\n",
    " (7.0737562512314449, 0.8821159241146929),\n",
    " (5.5158907409668556, 2.287657630597947),\n",
    " (5.2424711689478309, 3.4418528431658317),\n",
    " (11.826235109408199, 3.3038133315910185),\n",
    " (6.2478202112864949, 3.7493402648869223),\n",
    " (7.2776616254733053, 2.666108760536187),\n",
    " (14.728663233221567, 5.923646379789856),\n",
    " (11.088563226667782, 2.974838497958867),\n",
    " (11.458847468046265, 1.2931851555147837),\n",
    " (4.0709653063610656, 2.4390760560779694),\n",
    " (15.530850378396899, 0.7685325485891545),\n",
    " (11.615168564683962, 2.7271570577326223),\n",
    " (10.632288760396049, 5.37570954124343),\n",
    " (6.9102179020649883, 1.9530381191410195),\n",
    " (7.1344237045084675, 1.6373486764522571),\n",
    " (2.4211573415830188, 2.810112760589519),\n",
    " (7.6108111175276107, 4.181915055702122),\n",
    " (9.6538205198090434, 4.444382820070389),\n",
    " (8.1905132263562983, 3.0534156042900285),\n",
    " (7.4546566492388493, 5.388475797989607),\n",
    " (14.087818085722649, 4.961727257154151),\n",
    " (7.2780971375915371, 2.54178907740794),\n",
    " (13.49355600611988, 2.493864649506947),\n",
    " (7.1166182479555999, 3.0195450895358524),\n",
    " (13.861336288014931, 6.246482002469356),\n",
    " (9.9498449141955589, 1.5817110088866608),\n",
    " (12.090250168282912, 3.990269038499848),\n",
    " (14.0111497595614, 0.9108297343631235),\n",
    " (9.3928518482934216, 3.3950553805254793),\n",
    " (8.2709147406350212, 3.214121983305056),\n",
    " (8.386404092046515, 2.1119573572471135),\n",
    " (6.9673744914092852, 2.2083135342567983),\n",
    " (9.5162641851488523, 3.2184133097802943),\n",
    " (17.967580316152478, 3.965622119805391),\n",
    " (15.832368008468372, 0.828357131652206),\n",
    " (5.3317615928107358, 2.6644501925548774),\n",
    " (5.8971983697046877, 3.0341229253117494),\n",
    " (17.963906775041007, 6.0469989006758444),\n",
    " (5.6300726881847361, 2.4077579346402826),\n",
    " (11.348534324413565, 3.8699231013565725),\n",
    " (10.028167958705753, 1.9397974132848168),\n",
    " (14.062219131934697, 4.41603067403343),\n",
    " (9.10707255345568, 0.8011371320017451),\n",
    " (10.567716164156263, 4.450436137829604),\n",
    " (10.928830310193101, 4.839816330906595),\n",
    " (11.681478622619728, 0.8572196990559613),\n",
    " (11.538949263967641, 5.760338188965996),\n",
    " (10.978084516398958, 4.49756314191279),\n",
    " (12.818751132975834, 4.411544813273495),\n",
    " (6.7181748281785731, 5.484421751460473)]\n",
    "\n",
    "\n",
    "def lnprob(x):\n",
    "    N = len(data)\n",
    "    if x[3] < 0 or x[2] > (2*np.pi) or x[2] < 0:\n",
    "        return -np.infty\n",
    "    else:\n",
    "        #return(-0.5*x[3] * np.sum([(e[0]-(x[0] + ((x[1]*(np.sin(e[1])+ x[2] *np.cos(e[1]))))))**2 for e in data]) + 0.5*N*np.log(x[3]) - 0.5*(x[0]**2+ x[1]**2 + x[2]**2) - x[3])\n",
    "        return(-0.5*x[3] * np.sum([(e[0]-(x[0] + ((x[1]*(x[2]*np.sin(e[1])*np.cos(e[1]))))))**2 for e in data]) + 0.5*N*np.log(x[3]) - 0.5*(x[0]**2+ x[1]**2 + x[2]**2) - x[3])\n",
    "class bayes:\n",
    "\n",
    "\n",
    "    def __init__(self, lnprob):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import matplotlib\n",
    "        from matplotlib import pyplot as plt\n",
    "        #self.data2 = data\n",
    "        self.lnprob = lnprob\n",
    "\n",
    "\n",
    "\n",
    "    def create_scatter_plot(self, data2):\n",
    "        data3 = pd.DataFrame(data2) # converted data into panda dataframe\n",
    "        data4 = data2\n",
    "        X1 = sum([x[1] for x in data2])\n",
    "        T = sum([x[0] for x in data2])\n",
    "        X2 = sum([x[1]**2 for x in data2])\n",
    "        T2 = sum([x[0]**2 for x in data2])\n",
    "        XT = sum([x[1]*x[0] for x in data2])\n",
    "        N = len(data2)\n",
    "        self.DeployEMCEE(data4, data3)\n",
    "        #print X1\n",
    "        #return data4, data3\n",
    "\n",
    "    def MonteCarlo(self,f, samples):\n",
    "        N = len(samples)\n",
    "        return 1 / float(N) * sum([f(e) for e in samples])\n",
    "\n",
    "    def set_walkers(self):\n",
    "        walkers = int(raw_input(\"please select an even number of walkers\"))\n",
    "        if walkers % 2 == 0:\n",
    "          pass\n",
    "        else:\n",
    "           walkers = int(raw_input(\"You did not select an even number of walkers to input please try again: \"))\n",
    "        return walkers\n",
    "\n",
    "\n",
    "    def set_dimensions(self):\n",
    "        ndim = int(raw_input(\"please select the number of dimensions Hint: there are four dimensions!\"))\n",
    "        return ndim\n",
    "\n",
    "    def DeployEMCEE(self, data4, data3):\n",
    "        import emcee\n",
    "        import time\n",
    "        \n",
    "        ndim = self.set_dimensions()\n",
    "        nwalkers = self.set_walkers()\n",
    "        print \"Go grab some decaf coffee this might take awhile!\"\n",
    "        start = time.time()\n",
    "        p0 = np.random.rand(nwalkers * ndim).reshape((nwalkers, ndim)) *10\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, self.lnprob)\n",
    "        pos, prob, state = sampler.run_mcmc(p0, 1000)\n",
    "        sampler.reset()\n",
    "        pos, prob, state = sampler.run_mcmc(pos, 100000)\n",
    "        samples = sampler.flatchain\n",
    "        end = time.time()\n",
    "        timetaken = end - start\n",
    "\n",
    "\n",
    "        omega0 = self.MonteCarlo(lambda x: x[0], samples)\n",
    "        omega1 = self.MonteCarlo(lambda x: x[1], samples)\n",
    "        omega2 = self.MonteCarlo(lambda x: x[2], samples)\n",
    "        #omega3 = self.MonteCarlo(lambda x: x[3], samples)\n",
    "        lam = self.MonteCarlo(lambda x: x[3], samples)\n",
    "        print ('o0 = {0}, o1 = {1}, o2 = {2}, l = {3}'.format(omega0, omega1, omega2, lam))\n",
    "        self.plot_linear(data3, omega0,omega1,omega2)\n",
    "        self.plot_prmtrs_dnsty(samples)\n",
    "        self.predictive(samples)\n",
    "        self.corner_plt(samples)\n",
    "        plt.show()\n",
    "        self.probhigher15(samples)\n",
    "        self.problower5(samples)\n",
    "        print 'done'\n",
    "        print \"Your runtime in seconds {0}\".format(timetaken)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def plot_linear(self, data3, omega0,omega1,omega2):\n",
    "        X = data3[0]\n",
    "        T = data3[1]\n",
    "        Xval = np.arange(0, 11)\n",
    "        Reg = [omega0 + omega1 * np.sin(omega2*x) for x in Xval]\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "        ax.scatter(T, X)\n",
    "        ax.plot(Xval, Reg, label='Regression', color='red')\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel('$X_t$')\n",
    "        ax.legend(loc='best', fontsize='small')\n",
    "        ax.grid();\n",
    "\n",
    "    \n",
    "    def plot_prmtrs_dnsty(self, samples):\n",
    "        data3 = pd.DataFrame(samples, columns=['Omega0', 'Omega1', 'Omega2', 'Lambda'])\n",
    "        data3.plot(kind='density', xlim =(-5, 10), ylim = (0,5))\n",
    "        \n",
    "    def corner_plt(self, samples):\n",
    "        import corner\n",
    "        fig = corner.corner(samples, labels=[\"$\\omega_0$\", \"$\\omega_1$\",\"$\\omega_2$\",\"$\\lambda$\"])\n",
    "\n",
    "    def predictive(self, samples):\n",
    "        f = lambda x, t: lambda d: np.sqrt(d[3]/(2*np.pi))*np.exp(-0.5*(x - (d[0] + d[1]*np.sin(t *d[2]))**2))\n",
    "        predictiveDist = lambda t: np.vectorize(lambda x: self.MonteCarlo(lambda d: f(x,t)(d), samples))\n",
    "        X = np.arange(1, 50, 1)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "        ax.plot(X,predictiveDist(14)(X))\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel('$X_t$')\n",
    "    def probhigher15(self, samples):\n",
    "        print \"yes\"\n",
    "        f = lambda d: d[0] + d[1] * np.sin(d[2]*(np.random.uniform(0,2*np.pi,1)))\n",
    "        Filter1 = [1 for e in samples if f(e) >15]\n",
    "        print \"probability higher than fifteen: {0}\".format(len(Filter1)/float(len(samples)))\n",
    "    def problower5(self, samples):\n",
    "        f = lambda d: d[0] + d[1] * np.sin(d[2]*(np.random.uniform(0,2*np.pi,1)))\n",
    "        Filter1 = [1 for e in samples if f(e) <5]\n",
    "        print \"probability lower than five: {0}\".format(len(Filter1)/float(len(samples)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# please start me\n",
    "\n",
    "newcl = bayes(lnprob)\n",
    "newcl.create_scatter_plot(data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
